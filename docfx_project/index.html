<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>This is the HOMEPAGE. </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="This is the HOMEPAGE. ">
    <meta name="generator" content="docfx 2.40.0.0">
    
    <link rel="shortcut icon" href="favicon.ico">
    <link rel="stylesheet" href="styles/docfx.vendor.css">
    <link rel="stylesheet" href="styles/docfx.css">
    <link rel="stylesheet" href="styles/main.css">
    <meta property="docfx:navrel" content="toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="index.html">
                <img id="logo" class="svg" src="logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        <div class="article row grid">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">
              <p><a href="https://ci.appveyor.com/project/johniwasz/whetstone-alexa/branch/master"><img src="https://ci.appveyor.com/api/projects/status/qshnu4qyhtpv3m06/branch/master?svg=true" alt="Build status"></a></p>

              <h1 id="whetstonealexa">Whetstone Alexa</h1>
              
              <h2 id="introduction">Introduction</h2>
              
              <p>This goal of the Nuget package is:</p>
              
              <ul>
              <li>Provide POCO classes and serialization helpers to send and receive messages to and from Alexa</li>
              
              <li>Integrate with the Amazon's Alexa related services to:
              
              
              <ul>
              <li>Get users security information like the user name, device address, etc.</li></ul>
              </li>
              </ul>
              
              <h2 id="processingrequestsandresponses">Processing Requests and Responses</h2>
              
              <p>The Whetstone.Alexa Nuget package includes classes for serialization and deserializing common requests and responses passed to and from 
              Alexa Skills. The same structures apply irrespective of whether the client service is deployed as a web API or a Lambda Function. </p>
              
              <h3 id="webapisample">Web Api Sample</h3>
              
              <pre><code class="csharp language-csharp">using Microsoft.AspNetCore.Mvc;
              using Microsoft.Extensions.Logging;
              using Whetstone.Alexa;
              . . .
              
              namespace Whetstone.Alexa.EmailChecker.WebApi.Controllers
              {
                  [Produces("application/json")]
                  [Route("api/alexa")]
                  public class AlexaController : Controller
                  {       
                      [HttpPost]
                      public async Task&lt;ActionResult&gt; ProcessAlexaRequest([FromBody] AlexaRequest request)
                      {
                         AlexaResponse resp = await _emailProcessor.ProcessEmailRequestAsync(request);
                         return Ok(resp);
                      }
              </code></pre>
              
              <h3 id="lambdafunctionsample">Lambda Function Sample</h3>
              
              <p>```csharp
              using Amazon.Lambda.Core;
              using Whetstone.Alexa
              . . .</p>
              
              <p>// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.
              [assembly: LambdaSerializer(typeof(Amazon.Lambda.Serialization.Json.JsonSerializer))]</p>
              
              <p>namespace Whetstone.Alexa.EmailChecker.Lambda
              {
                  public class Function
                  {</p>
              
              <pre><code>    public async Task&lt;AlexaResponse&gt; FunctionHandlerAsync(AlexaRequest request, ILambdaContext context)
                  {
                      var emailProcessor = _serviceProvider.Value.GetRequiredService&lt;IEmailProcessor&gt;();
                      return await emailProcessor.ProcessEmailRequestAsync(request);     
                  }
              </code></pre>
              
              <pre><code>&lt;br/&gt;
              
              ## Processing the AlexaRequest
              
              The most useful values on the AlexaRequest is the [request type](https://developer.amazon.com/docs/custom-skills/request-types-reference.html), \
              [intent, and slot](https://developer.amazon.com/docs/custom-skills/create-the-interaction-model-for-your-skill.html#intents-and-slots) values. 
              
              Get the request type:
               ```csharp
              RequestType reqType = request.Request.Type;
              </code></pre>
              
              <p>Get the name of the intent:
               ```csharp
              string intent = request.Request.Intent.Name;</p>
              
              <pre><code>Get a slot value from the intent:
              </code></pre>
              
              <p>csharp
              string selectedCity = request.Request.Intent.GetSlotValue("city"); </p>
              
              <pre><code>## Create a Response
              Alexa can speak a plain text response to the user or process [Speech Synthesis Markup Language (SSML)](https://developer.amazon.com/docs/custom-skills/speech-synthesis-markup-language-ssml-reference.html).
              SSML include speech directives to tell change the volume of Alexa's voice, speed up or slow the response, and play MP3 files. The total time to provide the response the user cannot exceed 90 seconds. If the user
              does not respond, Alexa uses a [reprompt](https://developer.amazon.com/docs/custom-skills/request-and-response-json-reference.html#reprompt-object) to elicit a response from the user. Optionally, a
              card response can send plain text along with small images. Card responses appear in the user's Alexa mobile application and on alexa.amazon.com.
              &lt;br/&gt;
              &lt;br/&gt;
              The following sample sends a plain text response, a reprompt, and a standard card response.
              </code></pre>
              
              <p>csharp
              string textResp = "You are following a path in forest and have come to a fork. Would you like to go left or right?";
              AlexaResponse resp = new AlexaResponse
              {
                  Version = "1.0",
                  Response = new AlexaResponseAttributes
                  {
                      OutputSpeech = OutputSpeechBuilder.GetPlainTextSpeech(textResp),
                      Card = CardBuilder.GetSimpleCardResponse("Fork in the Road", textResp),
                      Reprompt = new RepromptAttributes
                      {
                          OutputSpeech = OutputSpeechBuilder.GetPlainTextSpeech("Left or right?"),
                      },
                      ShouldEndSession = false
                  },
              };</p>
              
              <pre><code>To include an image in the card response, provide a publicly accessible URL for both a small image (720w x 480h) and large image (1200w x 800h).
              For more information, please see [Create a Home Card to Display Text and an Image](https://developer.amazon.com/docs/custom-skills/include-a-card-in-your-skills-response.html#create-a-home-card-to-display-text-and-an-image).
              </code></pre>
              
              <p>csharp
                 . . .
                      Card = CardBuilder.GetStandardCardResponse("Fork in the Road",
                              textResponse,
                              "https://dev-customapp.s3.amazonaws.com/adventuregame/images/forkintheroad<em>720x800.png",
                              "https://dev-customapp.s3.amazonaws.com/adventuregame/images/forkintheroad</em>1200x800.png"
                              ),
                 . . .</p>
              
              <pre><code>### Embedding MP3 files and SSML Tags
              
              The following sample shows how to include MP3 files in the response using the audio tag along with supported SSML tags. For a comprehensive list of Alexa-supported SSML tags, please see [Speech Synthesis Markup Language (SSML) Reference](https://developer.amazon.com/docs/custom-skills/speech-synthesis-markup-language-ssml-reference.html).
              </code></pre>
              
              <p>csharp
                  StringBuilder ssmlSample = new StringBuilder();</p>
              
              <pre><code>ssmlSample.Append("&lt;speak&gt;&lt;audio src='https://dev-sbsstoryengine.s3.amazonaws.com/stories/animalfarmpi/audio/Act1-OpeningMusic-alexa.mp3'/&gt; ");
              ssmlSample.Append("It was a dark and stormy night. &lt;break time='500ms'/&gt;");
              ssmlSample.Append("&lt;say-as interpret-as='interjection'&gt;no way!&lt;/say-as&gt; ");
              ssmlSample.Append("I'm not doing this. That doesn’t make any sense!  That music didn’t sound dark and stormy at ");
              ssmlSample.Append("&lt;prosody volume='x-loud' pitch='+10%'&gt;all!&lt;/prosody&gt;");
              ssmlSample.Append(" It sounds to me more like a bright and chipper morning! Should we go with dark and stormy, or bright and chipper?");
              ssmlSample.Append("&lt;/speak&gt;")
              
              AlexaResponse resp = new AlexaResponse
              {
                  Version = "1.0",
                  Response = new AlexaResponseAttributes
                  {
                      OutputSpeech = OutputSpeechBuilder.GetSsmlSpeech(ssmlSample.ToString()),
              </code></pre>
              
              <pre><code>#### Using the Alexa Skills Kit Sound Library
              
              Amazon has provided a sound library that includes animal, game show, and other sounds. This may be a viable alternative if the needs for sounds is limited. The **Whetstone.Alexa** Nuget package includes 
              constants that link to all of the sounds provided in the [Alexa Skills Kit Sound Library](https://developer.amazon.com/docs/custom-skills/ask-soundlibrary.html).
              </code></pre>
              
              <p>csharp
              using Whetstone.Alexa.Audio.AmazonSoundLibrary;</p>
              
              <p>. . .</p>
              
              <pre><code>StringBuilder librarySample = new StringBuilder();
              librarySample.Append("&lt;speak&gt;");
              librarySample.Append(Office.ELEVATOR_BELL_1X_01);
              librarySample.Append("Your hotel is booked!");
              librarySample.Append("&lt;/speak&gt;");
              </code></pre>
              
              <pre><code># Media Hosting Tips
              
              If you'd like to include and reference MP3 files and images, they must be publicly available. If hosting on S3 storage, then use a [bucket policy](https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html) 
              to limit the public files only to directories need to be exposed.
              &lt;br/&gt;
              
              The following bucket policy exposes only the files in the audio and image subfolders to the public. 
              </code></pre>
              
              <p>json
              {
                  "Version": "2012-10-17",
                  "Statement": [
                      {
                          "Sid": "AddPerm",
                          "Effect": "Allow",
                          "Principal": "<em>",
                          "Action": "s3:GetObject",
                          "Resource": [
                              "arn:aws:s3:::bucketname/projects/</em>/audio/<em>",
                              "arn:aws:s3:::bucketname/projects/</em>/image/*"
                          ]
                      }
                  ]
              }</p>
              
              <pre><code>In order to allow the Alexa mobile app to download the image, CORS restrictions must allow for GET requests from ask-ifr-download.s3.amazonaws.com.
              </code></pre>
              
              <p>xml
              <?xml version="1.0" encoding="UTF-8"?>
              <corsconfiguration xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
              <corsrule>
                  <allowedorigin>http://ask-ifr-download.s3.amazonaws.com</allowedorigin>
                  <allowedmethod>GET</allowedmethod>
              </corsrule>
              <corsrule>
                  <allowedorigin>https://ask-ifr-download.s3.amazonaws.com</allowedorigin>
                  <allowedmethod>GET</allowedmethod>
              </corsrule>
              </corsconfiguration></p>
              
              <pre><code>## Sending Progressive Response
              
              If the skill invokes a third-party API or performs a database search, the response could be delayed by a few seconds. A blue light will flash on the Alexa device while waiting for a response and
               the user may get the impression the skill is no longer responding.
              &lt;br/&gt;
              A progressive response informs the user that the skill is processing the request. The **Whetstone.Alexa** Nuget package wraps this in an easy-to-use class.
              </code></pre>
              
              <p>csharp
              using Whetstone.Alexa.ProgressiveResponse;</p>
              
              <pre><code>  . . .
              
              private IProgressiveResponseManager _progMan;
              private ILogger _logger;
              
              public EmailProcessor(ILogger&lt;EmailProcessor&gt; logger, IProgressiveResponseManager progMan)
              {
                  _logger = logger;
                  _progMan = progMan;
              }
              
              public async Task&lt;AlexaResponse&gt; GetAlexaAsync(AlexaRequest req)
              {
                  try
                  {
                      await _progMan.SendProgressiveResponseAsync(req, "I'm working on it");
                  }
                  catch(Exception ex)
                  {
                      // Log the error, don't fail the call
                      _logger.LogError(ex, "Error sending progressive response");
              
                  }
              
                  AlexaResponse ret = await CallLongRunningProcess(req);
              </code></pre>
              
              <p>```</p>
              
              <h2 id="todo">TODO</h2>
              
              <p>The following enhancements are planned:</p>
              
              <ul>
              <li>Dialog state processing</li>
              
              <li>Streaming audio management using the <a href="https://developer.amazon.com/docs/custom-skills/audioplayer-interface-reference.html">AudioPlayer</a> Interface</li>
              </ul>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/WhetstoneTechnologies/Whetstone.Alexa/blob/origin/gh-pages/docfx_project/index.md/#L1" class="contribution-link">Improve this Doc</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="styles/docfx.js"></script>
    <script type="text/javascript" src="styles/main.js"></script>
  </body>
</html>
